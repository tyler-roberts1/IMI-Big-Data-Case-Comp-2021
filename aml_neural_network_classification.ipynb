{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMI Big Data Competition - Anti-money Laundring \n",
    "# Unsupervised classifcation approach\n",
    "\n",
    "This script identifies high-risk money laundering bank accounts using a simple neural network and newly designed features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import itertools\n",
    "from sklearn import metrics\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "import keras\n",
    "from sklearn import preprocessing\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading an efficiant neural network \n",
    "final_model = keras.models.load_model('NN_final_models/model18')\n",
    "final_model.summary()\n",
    "print(\"Number of processors available for parallel computing: \", mp.cpu_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Designing new features to be used in identifying high-risk money laundering accounts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_trans_features(cus_group):\n",
    "  by_mon = cus_group.groupby('month').sum()\n",
    "  n_mon = len(cus_group['month'].unique())\n",
    "\n",
    "  in_per_cnt_avg = np.nansum((by_mon['in_amt']/by_mon['in_cnt']).fillna(0))/13.0\n",
    "  in_per_cnt_std = np.sqrt(np.nanstd((by_mon['in_amt']/by_mon['in_cnt']).fillna(0))**2 * n_mon / 13.0)\n",
    "  out_per_cnt_avg = np.nansum((by_mon['out_amt']/by_mon['out_cnt']).fillna(0))/13.0\n",
    "  out_per_cnt_std = np.sqrt(np.nanstd((by_mon['out_amt']/by_mon['out_cnt']).fillna(0))**2 * n_mon / 13.0)\n",
    "  \n",
    "  in_amt_avg = np.nansum(by_mon['in_amt'])/13.0\n",
    "  in_amt_std = np.sqrt((np.nanstd(by_mon['in_amt']))**2 * n_mon / 13.0)\n",
    "  out_amt_avg = np.nansum(by_mon['out_amt'])/13.0\n",
    "  out_amt_std = np.sqrt((np.nanstd(by_mon['out_amt']))**2 * n_mon / 13.0)\n",
    "\n",
    "  amt_ratio_avg = np.nansum((by_mon['in_amt']/by_mon['out_amt']).replace(np.inf,0))/13.0\n",
    "  amt_ratio_std = np.sqrt(np.nanstd((by_mon['in_amt']/by_mon['out_amt']).replace(np.inf,0))**2 * n_mon / 13.0)\n",
    "\n",
    "  in_cnt_avg = np.nansum(by_mon['in_cnt'])/13.0\n",
    "  in_cnt_std = np.sqrt(np.nanstd(by_mon['in_cnt'])**2 * n_mon / 13.0)\n",
    "  out_cnt_avg = np.nansum(by_mon['out_cnt'])/13.0\n",
    "  out_cnt_std = np.sqrt(np.nanstd(by_mon['out_cnt'])**2 * n_mon / 13.0)\n",
    "\n",
    "  cnt_ratio_avg = np.nansum((by_mon['in_cnt']/by_mon['out_cnt']).replace(np.inf,0))/13.0\n",
    "  cnt_ratio_std = np.sqrt(np.nanstd((by_mon['in_cnt']/by_mon['out_cnt']).replace(np.inf,0))**2 * n_mon / 13.0)\n",
    "  \n",
    "  mon_cash_group = cus_group[cus_group['trsactn_type']=='cash'].groupby(by=['month']).sum()\n",
    "  mon_cheque_group = cus_group[cus_group['trsactn_type']=='cheque'].groupby(by=['month']).sum()\n",
    "  mon_visa_group = cus_group[cus_group['trsactn_type']=='visa'].groupby(by=['month']).sum()\n",
    "  mon_debit_group = cus_group[cus_group['trsactn_type']=='debit'].groupby(by=['month']).sum()\n",
    "  mon_amex_group = cus_group[cus_group['trsactn_type']=='amex'].groupby(by=['month']).sum()\n",
    "  \n",
    "  per_cash_in_amt_avg = np.nansum((mon_cash_group['in_amt']/by_mon['in_amt']).fillna(0).replace(np.inf,0))/13.0\n",
    "  per_cash_in_amt_std = np.sqrt(np.nanstd((mon_cash_group['in_amt']/by_mon['in_amt']).fillna(0).replace(np.inf,0))**2 * n_mon / 13.0)\n",
    "  per_cash_in_cnt_avg = np.nansum(mon_cash_group['in_cnt']/by_mon['in_cnt'].fillna(0).replace(np.inf,0)) / 13.0\n",
    "  per_cash_in_cnt_std = np.sqrt(np.nanstd((mon_cash_group['in_cnt']/by_mon['in_cnt']).fillna(0).replace(np.inf,0))**2 * n_mon / 13.0)\n",
    "  per_cash_out_amt_avg = np.nansum((mon_cash_group['out_amt']/by_mon['out_amt']).fillna(0).replace(np.inf,0))/13.0\n",
    "  per_cash_out_amt_std = np.sqrt(np.nanstd((mon_cash_group['out_amt']/by_mon['out_amt']).fillna(0).replace(np.inf,0))**2 * n_mon / 13.0)\n",
    "  per_cash_out_cnt_avg = np.nansum(mon_cash_group['out_cnt']/by_mon['out_cnt'].fillna(0).replace(np.inf,0)) / 13.0\n",
    "  per_cash_out_cnt_std = np.sqrt(np.nanstd((mon_cash_group['out_cnt']/by_mon['out_cnt']).fillna(0).replace(np.inf,0))**2 * n_mon / 13.0)\n",
    "\n",
    "  per_cheque_in_amt_avg = np.nansum((mon_cheque_group['in_amt']/by_mon['in_amt']).fillna(0).replace(np.inf,0))/13.0\n",
    "  per_cheque_in_amt_std = np.sqrt(np.nanstd((mon_cheque_group['in_amt']/by_mon['in_amt']).fillna(0).replace(np.inf,0))**2 * n_mon / 13.0)\n",
    "  per_cheque_in_cnt_avg = np.nansum(mon_cheque_group['in_cnt']/by_mon['in_cnt'].fillna(0).replace(np.inf,0)) / 13.0\n",
    "  per_cheque_in_cnt_std = np.sqrt(np.nanstd((mon_cheque_group['in_cnt']/by_mon['in_cnt']).fillna(0).replace(np.inf,0))**2 * n_mon / 13.0)\n",
    "  per_cheque_out_amt_avg = np.nansum((mon_cheque_group['out_amt']/by_mon['out_amt']).fillna(0).replace(np.inf,0))/13.0\n",
    "  per_cheque_out_amt_std = np.sqrt(np.nanstd((mon_cheque_group['out_amt']/by_mon['out_amt']).fillna(0).replace(np.inf,0))**2 * n_mon / 13.0)\n",
    "  per_cheque_out_cnt_avg = np.nansum(mon_cheque_group['out_cnt']/by_mon['out_cnt'].fillna(0).replace(np.inf,0)) / 13.0\n",
    "  per_cheque_out_cnt_std = np.sqrt(np.nanstd((mon_cheque_group['out_cnt']/by_mon['out_cnt']).fillna(0).replace(np.inf,0))**2 * n_mon / 13.0)\n",
    "\n",
    "  per_visa_in_amt_avg = np.nansum((mon_visa_group['in_amt']/by_mon['in_amt']).fillna(0).replace(np.inf,0))/13.0\n",
    "  per_visa_in_amt_std = np.sqrt(np.nanstd((mon_visa_group['in_amt']/by_mon['in_amt']).fillna(0).replace(np.inf,0))**2 * n_mon / 13.0)\n",
    "  per_visa_in_cnt_avg = np.nansum(mon_visa_group['in_cnt']/by_mon['in_cnt'].fillna(0).replace(np.inf,0)) / 13.0\n",
    "  per_visa_in_cnt_std = np.sqrt(np.nanstd((mon_visa_group['in_cnt']/by_mon['in_cnt']).fillna(0).replace(np.inf,0))**2 * n_mon / 13.0)\n",
    "  per_visa_out_amt_avg = np.nansum((mon_visa_group['out_amt']/by_mon['out_amt']).fillna(0).replace(np.inf,0))/13.0\n",
    "  per_visa_out_amt_std = np.sqrt(np.nanstd((mon_visa_group['out_amt']/by_mon['out_amt']).fillna(0).replace(np.inf,0))**2 * n_mon / 13.0)\n",
    "  per_visa_out_cnt_avg = np.nansum(mon_visa_group['out_cnt']/by_mon['out_cnt'].fillna(0).replace(np.inf,0)) / 13.0\n",
    "  per_visa_out_cnt_std = np.sqrt(np.nanstd((mon_visa_group['out_cnt']/by_mon['out_cnt']).fillna(0).replace(np.inf,0))**2 * n_mon / 13.0)\n",
    "\n",
    "  per_debit_in_amt_avg = np.nansum((mon_debit_group['in_amt']/by_mon['in_amt']).fillna(0).replace(np.inf,0))/13.0\n",
    "  per_debit_in_amt_std = np.sqrt(np.nanstd((mon_debit_group['in_amt']/by_mon['in_amt']).fillna(0).replace(np.inf,0))**2 * n_mon / 13.0)\n",
    "  per_debit_in_cnt_avg = np.nansum(mon_debit_group['in_cnt']/by_mon['in_cnt'].fillna(0).replace(np.inf,0)) / 13.0\n",
    "  per_debit_in_cnt_std = np.sqrt(np.nanstd((mon_debit_group['in_cnt']/by_mon['in_cnt']).fillna(0).replace(np.inf,0))**2 * n_mon / 13.0)\n",
    "  per_debit_out_amt_avg = np.nansum((mon_debit_group['out_amt']/by_mon['out_amt']).fillna(0).replace(np.inf,0))/13.0\n",
    "  per_debit_out_amt_std = np.sqrt(np.nanstd((mon_debit_group['out_amt']/by_mon['out_amt']).fillna(0).replace(np.inf,0))**2 * n_mon / 13.0)\n",
    "  per_debit_out_cnt_avg = np.nansum(mon_debit_group['out_cnt']/by_mon['out_cnt'].fillna(0).replace(np.inf,0)) / 13.0\n",
    "  per_debit_out_cnt_std = np.sqrt(np.nanstd((mon_debit_group['out_cnt']/by_mon['out_cnt']).fillna(0).replace(np.inf,0))**2 * n_mon / 13.0)\n",
    "\n",
    "  per_amex_in_amt_avg = np.nansum((mon_amex_group['in_amt']/by_mon['in_amt']).fillna(0).replace(np.inf,0))/13.0\n",
    "  per_amex_in_amt_std = np.sqrt(np.nanstd((mon_amex_group['in_amt']/by_mon['in_amt']).fillna(0).replace(np.inf,0))**2 * n_mon / 13.0)\n",
    "  per_amex_in_cnt_avg = np.nansum(mon_amex_group['in_cnt']/by_mon['in_cnt'].fillna(0).replace(np.inf,0)) / 13.0\n",
    "  per_amex_in_cnt_std = np.sqrt(np.nanstd((mon_amex_group['in_cnt']/by_mon['in_cnt']).fillna(0).replace(np.inf,0))**2 * n_mon / 13.0)\n",
    "  per_amex_out_amt_avg = np.nansum((mon_amex_group['out_amt']/by_mon['out_amt']).fillna(0).replace(np.inf,0))/13.0\n",
    "  per_amex_out_amt_std = np.sqrt(np.nanstd((mon_amex_group['out_amt']/by_mon['out_amt']).fillna(0).replace(np.inf,0))**2 * n_mon / 13.0)\n",
    "  per_amex_out_cnt_avg = np.nansum(mon_amex_group['out_cnt']/by_mon['out_cnt'].fillna(0).replace(np.inf,0)) / 13.0\n",
    "  per_amex_out_cnt_std = np.sqrt(np.nanstd((mon_amex_group['out_cnt']/by_mon['out_cnt']).fillna(0).replace(np.inf,0))**2 * n_mon / 13.0)\n",
    "\n",
    "  return pd.DataFrame({'in_per_cnt_avg':in_per_cnt_avg, 'in_per_cnt_std':in_per_cnt_std, \n",
    "                       'out_per_cnt_avg':out_per_cnt_avg, 'out_per_cnt_std':out_per_cnt_std,\n",
    "                       'in_amt_avg':in_amt_avg, 'in_amt_std':in_amt_std, \n",
    "                       'out_amt_avg':out_amt_avg, 'out_amt_std':out_amt_std,\n",
    "                       'per_cash_in_amt_avg':per_cash_in_amt_avg, 'per_cash_in_amt_std':per_cash_in_amt_std, \n",
    "                       'per_cash_in_cnt_avg':per_cash_in_cnt_avg, 'per_cash_in_cnt_std':per_cash_in_cnt_std,\n",
    "                       'per_cash_out_amt_avg':per_cash_out_amt_avg, 'per_cash_out_amt_std':per_cash_out_amt_std,\n",
    "                       'per_cash_out_cnt_avg':per_cash_out_cnt_avg, 'per_cash_out_cnt_std':per_cash_out_cnt_std,\n",
    "                       'per_cheque_in_amt_avg':per_cheque_in_amt_avg, 'per_cheque_in_amt_std':per_cheque_in_amt_std, \n",
    "                       'per_cheque_in_cnt_avg':per_cheque_in_cnt_avg, 'per_cheque_in_cnt_std':per_cheque_in_cnt_std,\n",
    "                       'per_cheque_out_amt_avg':per_cheque_out_amt_avg, 'per_cheque_out_amt_std':per_cheque_out_amt_std,\n",
    "                       'per_cheque_out_cnt_avg':per_cheque_out_cnt_avg, 'per_cheque_out_cnt_std':per_cheque_out_cnt_std,\n",
    "                       'per_visa_in_amt_avg':per_visa_in_amt_avg, 'per_visa_in_amt_std':per_visa_in_amt_std, \n",
    "                       'per_visa_in_cnt_avg':per_visa_in_cnt_avg, 'per_visa_in_cnt_std':per_visa_in_cnt_std,\n",
    "                       'per_visa_out_amt_avg':per_visa_out_amt_avg, 'per_visa_out_amt_std':per_visa_out_amt_std,\n",
    "                       'per_visa_out_cnt_avg':per_visa_out_cnt_avg, 'per_visa_out_cnt_std':per_visa_out_cnt_std,\n",
    "                       'per_debit_in_amt_avg':per_debit_in_amt_avg, 'per_debit_in_amt_std':per_debit_in_amt_std, \n",
    "                       'per_debit_in_cnt_avg':per_debit_in_cnt_avg, 'per_debit_in_cnt_std':per_debit_in_cnt_std,\n",
    "                       'per_debit_out_amt_avg':per_debit_out_amt_avg, 'per_debit_out_amt_std':per_debit_out_amt_std,\n",
    "                       'per_debit_out_cnt_avg':per_debit_out_cnt_avg, 'per_debit_out_cnt_std':per_debit_out_cnt_std,\n",
    "                       'per_amex_in_amt_avg':per_amex_in_amt_avg, 'per_amex_in_amt_std':per_amex_in_amt_std, \n",
    "                       'per_amex_in_cnt_avg':per_amex_in_cnt_avg, 'per_amex_in_cnt_std':per_amex_in_cnt_std,\n",
    "                       'per_amex_out_amt_avg':per_amex_out_amt_avg, 'per_amex_out_amt_std':per_amex_out_amt_std,\n",
    "                       'per_amex_out_cnt_avg':per_amex_out_cnt_avg, 'per_amex_out_cnt_std':per_amex_out_cnt_std,},index=[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading the transaction file\n",
    "#Ensure the training file is in the current working directory\n",
    "df_trans = pd.read_parquet(\"bigdata2021data/transaction_train.parquet\")\n",
    "df_trans_by_cus = df_trans.groupby('customer_id_mskd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Computing the new features and adding them to the existing dataframe\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(nb_workers=np.int(mp.cpu_count()/2))\n",
    "df_trans_features = df_trans_by_cus.parallel_apply(compute_trans_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scaling all features for use in further analyses and ensuring that using the .head() command\n",
    "df_trans_features.iloc[:,:] = preprocessing.StandardScaler().fit_transform(df_trans_features)\n",
    "df_trans_features.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting all customer ID's from the transaction dataframe and amount of unique customers\n",
    "cus_id = df_trans_features.index.unique()\n",
    "len(cus_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the separate customer data file and only retriving information pertaining to \n",
    "#the customers that are in the transaction file\n",
    "df_cus = pd.read_parquet('customer_training.parquet')\n",
    "df_cus = df_cus.set_index('customer_id_mskd')\n",
    "df_cus = df_cus.loc[cus_id,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping empty columns or columns with incomplete data\n",
    "#Turning true/false values to boolean logic\n",
    "#Replacing NA's with 0's\n",
    "df_cus = df_cus.drop(columns=['client_type_aml','primary_ownership_flag','industry_code_aml','occupation_code_aml','jurisdiction_code',\n",
    "                              'customer_status_aml','country_of_domicile_aml','PCD_LLC','PCD_MOR','PCD_SAV','PCD_SDB','PCD_TED',\n",
    "                              'export_ts','PCD_CMS','PCD_MUF','SRV_FLG','SRV_FSL',\n",
    "                              'SRV_FLG','SRV_FSL','SRV_ILC','SRV_LOC','SRV_NLG','SRV_NSL','SRV_TRF'])\n",
    "df_cus[\"PCD_CDA\"].fillna(0,inplace=True)\n",
    "df_cus[\"PCD_CRC\"].fillna(0,inplace=True)\n",
    "df_cus['PRD_INFO_AVAIL'].replace({False:0, True:1}, inplace=True)\n",
    "df_cus = df_cus.merge(pd.get_dummies(df_cus[['occupation_status_code_aml','relationship_type']]),on='customer_id_mskd')\n",
    "df_cus.drop(columns=['occupation_status_code_aml','relationship_type'],inplace=True)\n",
    "df_cus[['relationship_type_POWER OF ATTORNEY','relationship_type_Power of Attorney']]=0\n",
    "df_cus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging customer and transaction data into one array for further analyses\n",
    "df_combined = df_trans_features.merge(df_cus,on='customer_id_mskd')\n",
    "df_combined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building and testing the model using NN and Kmeans Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import cluster\n",
    "\n",
    "# function to do kmeans and add data to dataframe\n",
    "\n",
    "def do_kmeans(df, feats_use, k = 12, col_name = 'cluster'):\n",
    "    # df = pandas DataFrame with numeric features\n",
    "    # feats_use = list or array features columns to subset\n",
    "    # modifies dataframe to contain cluster labels\n",
    "    data_use = df[feats_use].to_numpy().astype('float64')\n",
    "    # setup + run kmeans\n",
    "    kmeans_obj = cluster.KMeans(n_clusters = k, random_state = 20)\n",
    "    clust_labs = kmeans_obj.fit_predict(data_use)\n",
    "    # conver clust_labs to string (categorical)\n",
    "    clust_labs = clust_labs.astype('str')\n",
    "    df[col_name] = clust_labs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the values for input into our model\n",
    "X_big = df_combined.values\n",
    "y_big = final_model.predict(X_big)\n",
    "y_lab = y_big.argmax(axis=1)\n",
    "df_lab_3 = df_combined.iloc[y_lab==2,:]\n",
    "\n",
    "do_kmeans(df_lab_3, feats_use = df_lab_3.columns, k = 2, col_name = 'clust')\n",
    "\n",
    "df_lab_3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
