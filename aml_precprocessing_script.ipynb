{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMI Big Data Competition - Anti-money Laundring \n",
    "# Data Preprocessing\n",
    "\n",
    "#This script preprocesses the AML data and output a merged data\n",
    "\n",
    "#import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "## Inspect data\n",
    "### Customer data set\n",
    "\n",
    "The customer data set contains customer-level data on retail accounts for which we have labels\n",
    "\n",
    "Columns:\n",
    "* The first five columns correspond to information given by the customer\n",
    "* The variable \"rating\" means risk of AML: 1 = low risk, 2 = medium risk, 3 = potentially high risk\n",
    "* Columns beginning with “PCD” or “SRV” correspond to ‘product’ or ‘account’ information (e.g., PCD_MOR: how many accounts of type “MOR” does this customer have)\n",
    "\n",
    "#Load the customer training data set\n",
    "df_cust = pd.read_parquet(\"cust_train.parquet\")\n",
    "df_cust.head()\n",
    "\n",
    "#See what dtypes are contained in the dataframe\n",
    "df_cust.info()\n",
    "\n",
    "#Remove columns that only contain NaNs (i.e., the number of NaNs is equal to the number of rows)\n",
    "nanCols = df_cust.columns[df_cust.isna().sum()==len(df_cust)] #columns that only contain NaNs\n",
    "#remove these columns\n",
    "df_cust.drop(nanCols, axis=1, inplace=True) \n",
    "\n",
    "#Descriptive statistics to get an early idea of any potential obvious pattersn upfront\n",
    "df_cust.describe()\n",
    "\n",
    "### Transaction data set\n",
    "\n",
    "The transaction data set contains monthly aggregated transaction data on retail accounts in the customer data set\n",
    "\n",
    "Columns:\n",
    "* \"in_amt\" and \"out_amt\": The total volume entering and exiting each product for each customer\n",
    "* \"in_cnt\" and \"out_cnt\": The total count of transactions over which that volume was distributed\n",
    "\n",
    "#load the transaction training data set:\n",
    "df_trans = pd.read_parquet(\"transaction_train.parquet\")\n",
    "df_trans.head()\n",
    "\n",
    "#See what dtypes are contained in the dataframe\n",
    "df_trans.info()\n",
    "\n",
    "#Descriptives again for the transaction data this time\n",
    "df_trans.describe()\n",
    "\n",
    "#Merging Customer and Transaction data\n",
    "#Unique customer id in the customer data set\n",
    "custID_cust_uniq = df_cust['customer_id_mskd'].unique()\n",
    "#number of uniqe customer id in the customer training data set\n",
    "print('Number of unique customer IDs in the customer data:', str(len(custID_cust_uniq)))\n",
    "\n",
    "#Unique customer id in the transaction training data set\n",
    "custID_trsact_uniq = df_trsact['customer_id_mskd'].unique()\n",
    "#number of uniqe customer id in the transaction training data set\n",
    "print('Number of unique customer IDs in the transaction data:', str(len(custID_trsact_uniq)))\n",
    "\n",
    "#Remove customers without transaction data when merging data sets\n",
    "df_merged = df_cust.merge(df_trans, on='customer_id_mskd')\n",
    "\n",
    "#Confirming dtypes in the new dataframe to ensure nothing changes\n",
    "df_merge.info()\n",
    "\n",
    "#Fill NaNs with zeros for coutinuous variables: PCD_CDA, ... PCD_TED, and in_amt, in_cnt, out_amt, out_cnt\n",
    "cols_cont = ['PCD_CDA','PCD_CRC','PCD_LLC','PCD_MOR','PCD_SAV','PCD_SDB','PCD_TED',\n",
    "            'in_amt','in_cnt','out_amt','out_cnt']\n",
    "\n",
    "#Check whether there is any values of zeros in the continuous variables\n",
    "#If there is no errors, we can replace missing values in these columns with zeros\n",
    "#If an error occurs, it means that column has at least 1 value of zero, and we need to think whether we can replace missing values with zeros\n",
    "for col in cols_cont:\n",
    "    assert (df_merged['PCD_CDA']==0).sum() == 0\n",
    "\n",
    "#Make sure that there is NO case when in_amt contains a value but in_cnt is NaN (same applies to out_amt and out_cnt)\n",
    "assert ~(df_trans['in_amt'].isna() ^ df_trans['in_cnt'].isna()).any()\n",
    "assert ~(df_trans['out_amt'].isna() ^ df_trans['out_cnt'].isna()).any()\n",
    "\n",
    "#Fill missing values with zeros\n",
    "for col in cols_cont:\n",
    "    df_merged.fillna({col: 0}, inplace=True)\n",
    "    \n",
    "df_merge.info()\n",
    "\n",
    "# Save the merged data as a parquet file\n",
    "df_merged.to_parquet(\"merged_clean_df.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
