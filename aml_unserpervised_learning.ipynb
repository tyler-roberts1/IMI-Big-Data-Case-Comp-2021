{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMI Big Data Competition - Anti-money Laundring \n",
    "# Unsupervised classifcation approach\n",
    "\n",
    "This script computes different models of unsupervised learning such as PCA, Clustering, and KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA\n",
    "\n",
    "Apply PCA on the continuous variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn import preprocessing, decomposition\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the clean merge data and view the dtypes contained\n",
    "rootDir = '/Users/Me/Local/Directory/'\n",
    "filePath = os.path.join(rootDir,'trans_each_yr.parquet')\n",
    "trans_each_year_all = pd.read_parquet(filePath)\n",
    "trans_each_year_all.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract the continuous variables (features fed into PCA)\n",
    "merge_cont = merged_df[cols_cont]\n",
    "\n",
    "#Standardize the features\n",
    "scaler = preprocessing.StandardScaler()\n",
    "temp = scaler.fit_transform(merge_cont)\n",
    "merge_cont_zscored = pd.DataFrame(data=tmp, columns=cols_cont)\n",
    "del temp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup the PCA object applied on all continuous variables\n",
    "pca_cont = decomposition.PCA().fit(merge_cont_zscored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Explained variance and cumulative explained variance for each PC\n",
    "pcs_plot = np.arange(0,len(cols_cont))\n",
    "fig, (ax1,ax2) = plt.subplots(1,2, sharex=True, figsize=(10,5))\n",
    "ax1.plot(pcs_plot, pca_cont.explained_variance_ratio_[pcs_plot])\n",
    "ax1.set_xticks(pcs_plot)\n",
    "ax1.set_xlabel('PC')\n",
    "ax1.set_ylabel('Fraction Variance Explained')\n",
    "\n",
    "ax2.plot(np.cumsum(pca_cont.explained_variance_ratio_[pcs_plot]))\n",
    "#ax2.xticks(pcs_plot)`\n",
    "ax2.set_xlabel('PC')\n",
    "ax2.set_ylabel('Cumulative Explained Variance')\n",
    "ax2.grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Visualize loadings of the first few PCs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nPCs_ttl = len(pca_cont.components_) #number of PCs in total\n",
    "nPCs = 4 #first n PCs to be selected\n",
    "\n",
    "#Get loadings for PC, i.e. association of input features with each PC. Do for PC0, PC1, PC2, PC3\n",
    "loadings_mat = pca_cont.components_[0:nPCs, :]\n",
    "#4 components x 11 features\n",
    "loadings_mat.shape\n",
    "\n",
    "cols_pc = ['PC'+str(i) for i in range(nPCs_ttl)]\n",
    "loadings_df = pd.DataFrame(data = np.transpose(loadings_mat), \n",
    "                           index = cols_cont, \n",
    "                           columns = cols_pc[0:nPCs])\n",
    "loadings_df.shape\n",
    "sns.heatmap(loadings_df, xticklabels = True, yticklabels = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Ranking features for PC's 0-3\n",
    "loadings_df['PC0'].sort_values(ascending = False)\n",
    "loadings_df['PC1'].sort_values(ascending = False)\n",
    "loadings_df['PC2'].sort_values(ascending = False)\n",
    "loadings_df['PC3'].sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Plot features and visualize both the distribution fo data and association of features with data\n",
    "\n",
    "#PCA coordinates derived from standardized data\n",
    "pca_cont_coords = pca_cont.fit_transform(merge_cont_zscored)#[:, 0:nPCs]\n",
    "pca_cont_coords = pd.DataFrame(data = pca_cont_coords, columns = cols_pc)\n",
    "pca_cont_coords\n",
    "\n",
    "#Combine PC coordinates with the continuous variables as well as customer ratings (target)\n",
    "merge_cont_pcs = pd.concat([merge_cont, merged_df['rating'], merged_df['rating_lbl'], pca_cont_coords], axis = 1)\n",
    "merge_cont_pcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot2D_pcs(df, pc_x, pc_y, col_target, targets, colors):\n",
    "    '''\n",
    "    Plot a 2D scatter plot of PC scores\n",
    "    Inputs:\n",
    "        df - a dataframe containing the PC scores and the target column\n",
    "        pc_x - the name of the PC to be plotted on x-axis (needs to match the column name in df)\n",
    "        pc_y - the name of the PC to be plotted on y-axis (needs to match the column name in df)\n",
    "        col_target - column name of the target (e.g., a cateogrical variable) in df\n",
    "        targets - a list of unique values in the target column\n",
    "        colors - a list of colors to be used for each unique value in the target column\n",
    "    '''\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_xlabel(pc_x)\n",
    "    ax.set_ylabel(pc_y)\n",
    "    for target, color in zip(targets,colors):\n",
    "        idxToKeep = df[col_target] == target\n",
    "        ax.scatter(df.loc[idxToKeep, pc_x], df.loc[idxToKeep, pc_y],\n",
    "                   c = color,\n",
    "                   alpha=0.3)\n",
    "    ax.legend(targets)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Plot PC0 and PC1\n",
    "plot2D_pcs(df=merge_cont_pcs, pc_x='PC0', pc_y='PC1', \n",
    "           col_target='rating_lbl', \n",
    "           targets=['low', 'medium', 'high'],\n",
    "           colors=['green','blue','red'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Plot PC2 and PC3\n",
    "plot2D_pcs(df=merge_cont_pcs, pc_x='PC2', pc_y='PC3', \n",
    "           col_target='rating_lbl', \n",
    "           targets=['low', 'medium', 'high'],\n",
    "           colors=['green','blue','red'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Plot PC4 and PC5\n",
    "plot2D_pcs(df=merge_cont_pcs, pc_x='PC4', pc_y='PC5', \n",
    "           col_target='rating_lbl', \n",
    "           targets=['low', 'medium', 'high'],\n",
    "           colors=['green','blue','red'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing packages\n",
    "from sklearn import cluster, metrics, preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_kmeans(df, feats_use, k = 2, scale = 'yes'): #, col_name = 'cluster'\n",
    "    #df = pandas DataFrame with numeric features\n",
    "    #feats_use = list or array features columns to subset\n",
    "    #modifies dataframe to contain cluster labels\n",
    "    \n",
    "    #if the features in df are not standardized yet\n",
    "    if scale=='yes':\n",
    "        df_raw = df.copy()\n",
    "        scaler = preprocessing.StandardScaler()\n",
    "        tmp = scaler.fit_transform(df[feats_use])\n",
    "        df = pd.DataFrame(data=tmp, columns=feats_use)\n",
    "        del tmp\n",
    "        \n",
    "    data_use = df[feats_use].to_numpy().astype('float64')   \n",
    "    kmeans_obj = cluster.KMeans(init='k-means++', n_clusters = k, random_state = 42)\n",
    "    clust_labs = kmeans_obj.fit_predict(data_use)\n",
    "    clust_labs = clust_labs.astype('str')\n",
    "    \n",
    "    return clust_labs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Means (k-means++) on the following variables (standardized) in merge_df\n",
    "* in_frac, in_cnt\n",
    "* out_frac, out_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Features to be used\n",
    "cols_feat = ['in_frac','in_cnt','out_frac','out_cnt']\n",
    "\n",
    "#Remove rows with NaN in in_frac and out_frac\n",
    "merged_df_frac = merged_df.dropna(subset=['in_frac','out_frac'])\n",
    "\n",
    "#Do clustering\n",
    "nClusters = 3\n",
    "clust3_lbl_frac = do_kmeans(merged_df_frac, feats_use=cols_feat, k=nClusters)\n",
    "\n",
    "clust3_lbl_frac_df = pd.DataFrame(data=clust3_lbl_frac,\n",
    "                                  index=merged_df_frac.index).rename(columns={0:'clust3_lbl'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the silhouette score (higher means better clustering performance)\n",
    "s_score = metrics.silhouette_score(merges_df_frac[cols_feat], clust3_lbl_frac, metric=\"euclidean\")\n",
    "print('Number of clusters =', str(nClusters), ': Silhouette score =', str(s_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Plot Count of IN vs. IN money per transaction\n",
    "fig, (ax1, ax2) = plt.subplots(1,2, sharex=True, sharey=True, figsize=(14,5))\n",
    "\n",
    "#clustering label\n",
    "ax1.set_xlabel('Count of Deposit') \n",
    "ax1.set_ylabel('Deposit Money per Transaction') \n",
    "targets = ['0', '1', '2']\n",
    "colors = ['c', 'm', 'y']\n",
    "for target, color in zip(targets,colors):\n",
    "    indicesToKeep = clust3_lbl_frac_df['clust3_lbl']==target\n",
    "    ax1.scatter(merge_df_frac.loc[indicesToKeep, 'in_cnt']\n",
    "               , merge_df_frac.loc[indicesToKeep, 'in_frac']\n",
    "               , c = color\n",
    "               , alpha=0.3)\n",
    "ax1.set_title('Clustering labels')\n",
    "ax1.legend(targets)\n",
    "\n",
    "#risk rating\n",
    "ax2.set_xlabel('Count of Deposit') \n",
    "ax2.set_ylabel('Deposit Money per Transaction') \n",
    "targets = ['low', 'medium', 'high']\n",
    "colors = ['g', 'b', 'r']\n",
    "for target, color in zip(targets,colors):\n",
    "    indicesToKeep = merge_df_frac['rating_lbl'] == target\n",
    "    ax2.scatter(merge_df_frac.loc[indicesToKeep, 'in_cnt']\n",
    "               , merge_df_frac.loc[indicesToKeep, 'in_frac']\n",
    "               , c = color\n",
    "               , alpha=0.3)\n",
    "ax2.set_title('Risk ratings')\n",
    "ax2.legend(targets)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot Count of OUT vs. OUT money per transaction\n",
    "fig, (ax1, ax2) = plt.subplots(1,2, sharex=True, sharey=True, figsize=(14,5))\n",
    "\n",
    "#clustering label\n",
    "ax1.set_xlabel('Count of Withdrawl') \n",
    "ax1.set_ylabel('Withdrawl Money per Transaction') \n",
    "targets = ['0', '1', '2']\n",
    "colors = ['c', 'm', 'y']\n",
    "for target, color in zip(targets,colors):\n",
    "    indicesToKeep = clust3_lbl_frac_df['clust3_lbl']==target\n",
    "    ax1.scatter(merge_df_frac.loc[indicesToKeep, 'out_cnt']\n",
    "               , merge_df_frac.loc[indicesToKeep, 'out_frac']\n",
    "               , c = color\n",
    "               , alpha=0.3)\n",
    "ax1.set_title('Clustering labels')\n",
    "ax1.legend(targets)\n",
    "\n",
    "#risk rating\n",
    "ax2.set_xlabel('Count of Withdrawl') \n",
    "ax2.set_ylabel('Withdrawl Money per Transaction') \n",
    "targets = ['low', 'medium', 'high']\n",
    "colors = ['g', 'b', 'r']\n",
    "for target, color in zip(targets,colors):\n",
    "    indicesToKeep = merge_df_frac['rating_lbl'] == target\n",
    "    ax2.scatter(merge_df_frac.loc[indicesToKeep, 'out_cnt']\n",
    "               , merge_df_frac.loc[indicesToKeep, 'out_frac']\n",
    "               , c = color\n",
    "               , alpha=0.3)\n",
    "ax2.set_title('Risk ratings')\n",
    "ax2.legend(targets)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Means (k-means++) on all continuous variables (standardized) in merge_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clustering\n",
    "nClusters = 3\n",
    "clust3_lbl = do_kmeans(merge_df, feats_use=cols_cont, k=nClusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the silhouette score (higher means better clustering performance)\n",
    "s_score = metrics.silhouette_score(merge_cont_zscored[cols_cont], clust3_lbl, metric=\"euclidean\")\n",
    "print('Number of clusters =', str(nClusters), ': Silhouette score =', str(s_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compare the clustering labels and the customer risk rating labels\n",
    "clust3_lbl_df = pd.DataFrame(data=clust3_lbl).rename(columns={0:'clust3_lbl'})\n",
    "clust3_rating = pd.concat([clust3_lbl_df, merge_df['rating_lbl']], axis=1)\n",
    "clust3_rating.groupby(['clust3_lbl','rating_lbl']).size().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the K-Means (3 clusters) results along the first PC0 and PC1\n",
    "#Also plot the rating labels just for comparison\n",
    "sel_pcs = [0,1]\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1,2,sharex=True, sharey=True, figsize=(10,5))\n",
    "ax1.set_xlabel(cols_pc[sel_pcs[0]])\n",
    "ax1.set_ylabel(cols_pc[sel_pcs[1]])\n",
    "targets = ['0', '1', '2']\n",
    "colors = ['c', 'm', 'y']\n",
    "for target, color in zip(targets,colors):\n",
    "    indicesToKeep = clust3_lbl_df['clust3_lbl']==target #merge_cont_zscored['clustLbls_k3'] == target\n",
    "    ax1.scatter(merge_cont_pcs.loc[indicesToKeep, cols_pc[sel_pcs[0]]]\n",
    "               , merge_cont_pcs.loc[indicesToKeep, cols_pc[sel_pcs[1]]]\n",
    "               , c = color\n",
    "               , alpha=0.3)\n",
    "ax1.legend(targets)\n",
    "\n",
    "ax2.set_xlabel(cols_pc[sel_pcs[0]])\n",
    "ax2.set_ylabel(cols_pc[sel_pcs[1]])\n",
    "targets = ['low', 'medium', 'high']\n",
    "colors = ['g', 'b', 'r']\n",
    "for target, color in zip(targets,colors):\n",
    "    indicesToKeep = merge_cont_pcs['rating_lbl'] == target\n",
    "    ax2.scatter(merge_cont_pcs.loc[indicesToKeep, cols_pc[sel_pcs[0]]]\n",
    "               , merge_cont_pcs.loc[indicesToKeep, cols_pc[sel_pcs[1]]]\n",
    "               , c = color\n",
    "               , alpha=0.3)\n",
    "ax2.legend(targets)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the K-Means (3 clusters) results along PC2 and PC3\n",
    "#Also plot the rating labels just for comparison\n",
    "sel_pcs = [2,3]\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1,2,sharex=True, sharey=True, figsize=(10,5))\n",
    "ax1.set_xlabel(cols_pc[sel_pcs[0]])\n",
    "ax1.set_ylabel(cols_pc[sel_pcs[1]])\n",
    "targets = ['0', '1', '2']\n",
    "colors = ['c', 'm', 'y']\n",
    "for target, color in zip(targets,colors):\n",
    "    indicesToKeep = clust3_lbl_df['clust3_lbl']==target #merge_cont_zscored['clustLbls_k3'] == target\n",
    "    ax1.scatter(merge_cont_pcs.loc[indicesToKeep, cols_pc[sel_pcs[0]]]\n",
    "               , merge_cont_pcs.loc[indicesToKeep, cols_pc[sel_pcs[1]]]\n",
    "               , c = color\n",
    "               , alpha=0.3)\n",
    "ax1.legend(targets)\n",
    "\n",
    "ax2.set_xlabel(cols_pc[sel_pcs[0]])\n",
    "ax2.set_ylabel(cols_pc[sel_pcs[1]])\n",
    "targets = ['low', 'medium', 'high']\n",
    "colors = ['g', 'b', 'r']\n",
    "for target, color in zip(targets,colors):\n",
    "    indicesToKeep = merge_cont_pcs['rating_lbl'] == target\n",
    "    ax2.scatter(merge_cont_pcs.loc[indicesToKeep, cols_pc[sel_pcs[0]]]\n",
    "               , merge_cont_pcs.loc[indicesToKeep, cols_pc[sel_pcs[1]]]\n",
    "               , c = color\n",
    "               , alpha=0.3)\n",
    "ax2.legend(targets)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means on the data summed across months (No matter what types of transactions)\n",
    "### K-Means (k-means++) on the following variables (standardized) in merge_yr\n",
    "* in_frac, in_cnt\n",
    "* out_frac, out_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Features to be used\n",
    "cols_feat = ['in_frac','in_cnt','out_frac','out_cnt']\n",
    "\n",
    "#Remove rows with NaN in in_frac and out_frac\n",
    "merge_year_frac = merge_year.dropna(subset=['in_frac','out_frac'])\n",
    "\n",
    "#Do clustering\n",
    "nClusters = 3\n",
    "clust3_lbl_year_frac = do_kmeans(merge_year_frac, feats_use=cols_feat, k=nClusters)\n",
    "clust3_lbl_year_frac_df = pd.DataFrame(data=clust3_lbl_year_frac,index=merge_year_frac.index).rename(columns={0:'clust3_lbl'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the silhouette score (higher means better clustering performance)\n",
    "s_score = metrics.silhouette_score(merge_yr_frac[cols_feat], clust3_lbl_yr_frac, metric=\"euclidean\")\n",
    "print('Number of clusters =', str(nClusters), ': Silhouette score =', str(s_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1,2, sharex=True, sharey=True, figsize=(14,5))\n",
    "\n",
    "#clustering label\n",
    "ax1.set_xlabel('Deposit Money per Transaction') #in_frac\n",
    "ax1.set_ylabel('Withdrawl Money per Transaction') #out_frac\n",
    "targets = ['0', '1', '2']\n",
    "colors = ['c', 'm', 'y']\n",
    "for target, color in zip(targets,colors):\n",
    "    indicesToKeep = clust3_lbl_year_frac_df['clust3_lbl']==target\n",
    "    ax1.scatter(merge_year_frac.loc[indicesToKeep, 'in_frac']\n",
    "               , merge_year_frac.loc[indicesToKeep, 'out_frac']\n",
    "               , c = color\n",
    "               , alpha=0.3)\n",
    "ax1.set_title('Clustering labels')\n",
    "ax1.legend(targets)\n",
    "\n",
    "#risk rating\n",
    "ax2.set_xlabel('Deposit Money per Transaction') #in_frac\n",
    "ax2.set_ylabel('Withdrawl Money per Transaction') #out_frac\n",
    "targets = ['low', 'medium', 'high']\n",
    "colors = ['g', 'b', 'r']\n",
    "for target, color in zip(targets,colors):\n",
    "    indicesToKeep = merge_year_frac['rating_lbl'] == target\n",
    "    ax2.scatter(merge_year_frac.loc[indicesToKeep, 'in_frac']\n",
    "               , merge_year_frac.loc[indicesToKeep, 'out_frac']\n",
    "               , c = color\n",
    "               , alpha=0.3)\n",
    "ax2.set_title('Risk ratings')\n",
    "ax2.legend(targets)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Means (k-means++) on all continuous variables (standardized) in merge_yr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do clustering\n",
    "nClusters = 3\n",
    "clust3_lbl_year = do_kmeans(merge_year, feats_use=cols_cont, k=nClusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the silhouette score (higher means better clustering performance)\n",
    "s_score = metrics.silhouette_score(merge_year[cols_cont], clust3_lbl_year, metric=\"euclidean\")\n",
    "print('Number of clusters =', str(nClusters), ': Silhouette score =', str(s_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compare the clustering labels and the customer risk rating labels\n",
    "clust3_lbl_year_df = pd.DataFrame(data=clust3_lbl_year).rename(columns={0:'clust3_lbl_year'})\n",
    "clust3_rating_year = pd.concat([clust3_lbl_year_df, merge_year['rating_lbl']], axis=1)\n",
    "clust3_rating_year.groupby(['clust3_lbl_year','rating_lbl']).size().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1,ax2) = plt.subplots(1,2, sharex=True, sharey=True, figsize=(14,5))\n",
    "\n",
    "#clustering label\n",
    "ax1.set_xlabel('Deposit money') #in_amt\n",
    "ax1.set_ylabel('Withdrawl money') #out_amt\n",
    "targets = ['0', '1', '2']\n",
    "colors = ['c', 'm', 'y']\n",
    "for target, color in zip(targets,colors):\n",
    "    indicesToKeep = clust3_lbl_year_df['clust3_lbl_year']==target #merge_cont_zscored['clustLbls_k3'] == target\n",
    "    ax1.scatter(merge_year.loc[indicesToKeep, 'in_amt']\n",
    "               , merge_year.loc[indicesToKeep, 'out_amt']\n",
    "               , c = color\n",
    "               , alpha=0.3)\n",
    "ax1.set_title('Clustering labels')\n",
    "ax1.legend(targets)\n",
    "\n",
    "\n",
    "#risk rating\n",
    "ax2.set_xlabel('Deposit money') #in_amt\n",
    "ax2.set_ylabel('Withdrawl money') #out_amt\n",
    "targets = ['low', 'medium', 'high']\n",
    "colors = ['g', 'b', 'r']\n",
    "for target, color in zip(targets,colors):\n",
    "    indicesToKeep = merge_year['rating_lbl'] == target\n",
    "    ax2.scatter(merge_year.loc[indicesToKeep, 'in_amt']\n",
    "               , merge_year.loc[indicesToKeep, 'out_amt']\n",
    "               , c = color\n",
    "               , alpha=0.3)\n",
    "ax2.set_title('Risk ratings')\n",
    "ax2.legend(targets)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means on the data summed across months (Only based on Cash transaction)\n",
    "### K-Means (k-means++) on the following variables (standardized) in merge_year\n",
    "* in_frac, in_cnt\n",
    "* out_frac, out_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Features to be used\n",
    "cols_feat = ['in_frac','in_cnt','out_frac','out_cnt']\n",
    "\n",
    "#Remove rows with NaN in in_frac and out_frac\n",
    "merge_year_frac_cash = merge_year[merge_year['trsactn_type']=='cash'].dropna(subset=['in_frac','out_frac'])\n",
    "\n",
    "#Clustering\n",
    "nClusters = 3\n",
    "clust3_lbl_year_frac_cash = do_kmeans(merge_year_frac_cash, feats_use=cols_feat, k=nClusters)\n",
    "clust3_lbl_year_frac_cash_df = pd.DataFrame(data=clust3_lbl_year_frac_cash,\n",
    "                                          index=merge_year_frac_cash.index).rename(columns={0:'clust3_lbl'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the silhouette score (higher means better clustering performance)\n",
    "s_score = metrics.silhouette_score(merge_year_frac_cash[cols_feat], clust3_lbl_year_frac_cash, metric=\"euclidean\")\n",
    "print('Number of clusters =', str(nClusters), ': Silhouette score =', str(s_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compare the clustering labels and the customer risk rating labels\n",
    "clust3_rating_year_frac_cash = pd.concat([clust3_lbl_year_frac_cash_df, merge_year_frac_cash['rating_lbl']], axis=1)\n",
    "clust3_rating_year_frac_cash.groupby(['clust3_lbl','rating_lbl']).size().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1,2, sharex=True, sharey=True, figsize=(14,5))\n",
    "\n",
    "#clustering label\n",
    "ax1.set_xlabel('Cash Deposit per Transaction') #in_frac\n",
    "ax1.set_ylabel('Cash Withdrawl per Transaction') #out_frac\n",
    "targets = ['0', '1', '2']\n",
    "colors = ['c', 'm', 'y']\n",
    "for target, color in zip(targets,colors):\n",
    "    indicesToKeep = clust3_lbl_year_frac_cash_df['clust3_lbl']==target\n",
    "    ax1.scatter(merge_year_frac_cash.loc[indicesToKeep, 'in_frac']\n",
    "               , merge_year_frac_cash.loc[indicesToKeep, 'out_frac']\n",
    "               , c = color\n",
    "               , alpha=0.3)\n",
    "ax1.set_title('Clustering labels')\n",
    "ax1.legend(targets)\n",
    "\n",
    "#risk rating\n",
    "ax2.set_xlabel('Cash Deposit per Transaction') #in_frac\n",
    "ax2.set_ylabel('Cash Withdrawl per Transaction') #out_frac\n",
    "targets = ['low', 'medium', 'high']\n",
    "colors = ['g', 'b', 'r']\n",
    "for target, color in zip(targets,colors):\n",
    "    indicesToKeep = merge_year_frac_cash['rating_lbl'] == target\n",
    "    ax2.scatter(merge_year_frac_cash.loc[indicesToKeep, 'in_frac']\n",
    "               , merge_year_frac_cash.loc[indicesToKeep, 'out_frac']\n",
    "               , c = color\n",
    "               , alpha=0.3)\n",
    "ax2.set_title('Risk ratings')\n",
    "ax2.legend(targets)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1,2, sharex=True, sharey=True, figsize=(14,5))\n",
    "\n",
    "#clustering label\n",
    "ax1.set_xlabel('Count of Cash Deposit') \n",
    "ax1.set_ylabel('Cash Deposit per Transaction') \n",
    "targets = ['0', '1', '2']\n",
    "colors = ['c', 'm', 'y']\n",
    "for target, color in zip(targets,colors):\n",
    "    indicesToKeep = clust3_lbl_year_frac_cash_df['clust3_lbl']==target\n",
    "    ax1.scatter(merge_year_frac_cash.loc[indicesToKeep, 'in_cnt']\n",
    "               , merge_year_frac_cash.loc[indicesToKeep, 'in_frac']\n",
    "               , c = color\n",
    "               , alpha=0.3)\n",
    "ax1.set_title('Clustering labels')\n",
    "ax1.legend(targets)\n",
    "\n",
    "#risk rating\n",
    "ax2.set_xlabel('Count of Cash Deposit') \n",
    "ax2.set_ylabel('Cash Deposit per Transaction') \n",
    "targets = ['low', 'medium', 'high']\n",
    "colors = ['g', 'b', 'r']\n",
    "for target, color in zip(targets,colors):\n",
    "    indicesToKeep = merge_year_frac_cash['rating_lbl'] == target\n",
    "    ax2.scatter(merge_year_frac_cash.loc[indicesToKeep, 'in_cnt']\n",
    "               , merge_year_frac_cash.loc[indicesToKeep, 'in_frac']\n",
    "               , c = color\n",
    "               , alpha=0.3)\n",
    "ax2.set_title('Risk ratings')\n",
    "ax2.legend(targets)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1,2, sharex=True, sharey=True, figsize=(14,5))\n",
    "\n",
    "#clustering label\n",
    "ax1.set_xlabel('Count of Cash Withdrawl') \n",
    "ax1.set_ylabel('Cash Withdrawl per Transaction') \n",
    "targets = ['0', '1', '2']\n",
    "colors = ['c', 'm', 'y']\n",
    "for target, color in zip(targets,colors):\n",
    "    indicesToKeep = clust3_lbl_year_frac_cash_df['clust3_lbl']==target\n",
    "    ax1.scatter(merge_year_frac_cash.loc[indicesToKeep, 'out_cnt']\n",
    "               , merge_year_frac_cash.loc[indicesToKeep, 'out_frac']\n",
    "               , c = color\n",
    "               , alpha=0.3)\n",
    "ax1.set_title('Clustering labels')\n",
    "ax1.legend(targets)\n",
    "\n",
    "#risk rating\n",
    "ax2.set_xlabel('Count of Cash Withdrawl') \n",
    "ax2.set_ylabel('Cash Withdrawl per Transaction') \n",
    "targets = ['low', 'medium', 'high']\n",
    "colors = ['g', 'b', 'r']\n",
    "for target, color in zip(targets,colors):\n",
    "    indicesToKeep = merge_year_frac_cash['rating_lbl'] == target\n",
    "    ax2.scatter(merge_year_frac_cash.loc[indicesToKeep, 'out_cnt']\n",
    "               , merge_year_frac_cash.loc[indicesToKeep, 'out_frac']\n",
    "               , c = color\n",
    "               , alpha=0.3)\n",
    "ax2.set_title('Risk ratings')\n",
    "ax2.legend(targets)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
